{
 "cells": [
  {
   "cell_type": "raw",
   "id": "3319bf1e-4ad3-4c49-9972-4cf838934a7a",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Visualization and Growth Curve modeling of CensusSeq iPSC lines\"\n",
    "format: \n",
    "    html:\n",
    "        theme: \n",
    "            - default\n",
    "        page-layout: full\n",
    "        code-fold: true\n",
    "        code-tools: true\n",
    "        toc: true\n",
    "        number-sections: true\n",
    "        embed-resources: true\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069e7e8a-796a-468c-916f-52164cef5333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "from matplotlib.lines import Line2D\n",
    "import yaml\n",
    "from scipy import stats\n",
    "\n",
    "import sys\n",
    "sys.path.append('../resources/')\n",
    "from ImagingUtilities import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import mean_squared_log_error, r2_score\n",
    "\n",
    "with open(\"../data/resources/rcParams.yaml\") as f:\n",
    "    rcParamsDict = yaml.full_load(f)\n",
    "    for k in rcParamsDict[\"rcParams\"]:\n",
    "        print(\"{} {}\".format(k,rcParamsDict[\"rcParams\"][k]))\n",
    "        plt.rcParams[k] = rcParamsDict[\"rcParams\"][k]\n",
    "    for k1 in set(list(rcParamsDict)).difference(set([\"rcParams\"])):\n",
    "        print(\"{} {}\".format(k1,rcParamsDict[k1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7232da9-50ce-4d1b-98d2-505327161d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_palette = {\n",
    " 'CTL01A': '#DBB807',\n",
    "    'CTL08A': '#0FB248',\n",
    "    'CTL04E': '#FF0054',\n",
    "    'CTL02A': '#7B00FF',\n",
    "'H9': '#72190E',\n",
    " 'H1': '#994F88',\n",
    " 'CTL05A': '#1965B0',\n",
    " 'CTL07C': '#437DBF',\n",
    " 'CTL06F': '#CAE0AB',\n",
    " 'CTL09A': '#FFFF00',\n",
    " 'KTD8.2': '#E65518',\n",
    " 'UCSFi001-A': '#7BAFDE'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670e3dc1-3f07-4bdf-8f7e-5399b6ba9a9a",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe844d4-c90b-4ded-80c5-7379a340ce65",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = pd.read_csv('../../iPSC_imaging/quantifications/quantification.csv', index_col=0)\n",
    "add_tp = pd.read_csv('../../iPSC_imaging/quantifications/quantification_addTP.csv', index_col=0)\n",
    "total_df[ ~ total_df.duplicated()]\n",
    "total_df = pd.concat([total_df, add_tp])\n",
    "\n",
    "donor_map_names = {i:j for i, j in zip(total_df['line'], total_df['line'])}\n",
    "donor_map_names['CHD2WT'] = 'UCSFi001-A'\n",
    "donor_map_names['CHD8WT'] = 'H9'\n",
    "total_df['line'] = total_df['line'].map(donor_map_names)\n",
    "total_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e085cb-0645-488f-862e-66d0858b0c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df['pixel_size'] = 1.38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f456d4-4b12-4094-b99f-7e46318f687b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df['Area (microm2)'] = total_df.total_area * 1.38\n",
    "total_df['Area (mm2)'] = total_df['Area (microm2)'] / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b61f1cc-5d47-40e5-9b06-a77f6a6f6520",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df['line'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e826d2d9-4ee8-455b-a883-63cd6ebdcb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tp = total_df.time_point.unique()\n",
    "all_tp.sort()\n",
    "all_tp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d9ae67-8501-4d54-b157-1eed90e1db86",
   "metadata": {},
   "source": [
    "Here I'm adding a few quantifications:\n",
    "\n",
    "1. `norm_factor`: the normalization factor, corresponding to the mean area of the area percentage of all lines for each time point post split (called `split_time`)\n",
    "2. `perc_area_norm`: the normalized percentage area, corresponding to the percentage area divided by the the normalization factor (1.)\n",
    "3. `mean_area_tp`: the mean area of each line at each time point post split (called `split_time`)\n",
    "4. `area_error`: the percentage \"error\" of the total area computed with respect to the mean of that line at that time point\n",
    "5. `std`: the standard deviation of each area with respect to (3.)\n",
    "6. `cv`: the [coefficient of variation](https://en.wikipedia.org/wiki/Coefficient_of_variation), corresponding to the ratio between the standard deviation and the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95041f39-ab68-4f7b-94e9-263d5c425141",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df['line_split'] = total_df['line'].astype('str') + '_' + total_df['split_time'].astype('str')\n",
    "\n",
    "mean_df_time_point = total_df.groupby(['split_time']).mean('perc_area')\n",
    "mean_df_time_point_dict = {i:j for i, j in zip(mean_df_time_point.index, mean_df_time_point.perc_area)}\n",
    "mean_df_time_point_dict\n",
    "\n",
    "area_df_time_point = total_df.groupby(['line','split_time']).mean('Area (microm2)').reset_index()\n",
    "area_df_time_point['line_split'] = area_df_time_point['line'].astype('str') + '_' + area_df_time_point['split_time'].astype('str')\n",
    "area_df_time_point = {i:j for i, j in zip(area_df_time_point.line_split, area_df_time_point['Area (microm2)'])}\n",
    "area_df_time_point\n",
    "\n",
    "total_df['norm_factor'] = total_df.split_time.map(mean_df_time_point_dict)\n",
    "total_df['perc_area_norm'] = total_df['perc_area'] / total_df['norm_factor']\n",
    "\n",
    "total_df['mean_area_tp'] = total_df.line_split.map(area_df_time_point)\n",
    "total_df['area_error'] = (total_df['mean_area_tp'] - total_df['Area (microm2)']) / total_df['Area (microm2)']\n",
    "total_df['std'] = np.sqrt((total_df['Area (microm2)'] - total_df['mean_area_tp'])**2 / len(total_df))\n",
    "total_df['cv'] = total_df['std'] / total_df['mean_area_tp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63af32a0-0e2e-4f55-bae2-230a776c2e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df['line_n_split'] = total_df['line'] + '_' + total_df['n_split'].astype('str')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ddb613bd-48ac-4c5e-8e24-8de976a49607",
   "metadata": {},
   "source": [
    "total_df['norm_factor_t0'] = total_df['line_n_split'].map(norm_area_dict)\n",
    "total_df['norm_area_t0'] = total_df['Area (microm2)'] / total_df['norm_factor_t0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edb9345-fea0-4ea2-aeab-2b6d3a697b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(total_df['cv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f109fb-4e14-4df4-88df-cdb6088b9cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.kdeplot(total_df['area_error'])\n",
    "ax.axvline(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9680d40e-6d06-4158-bbac-c7aa90dcba43",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.kdeplot(total_df['area_error'])\n",
    "ax.set_xlim(-1, 30)\n",
    "ax.axvline(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219cc19e-d842-46d3-b932-e4887b639ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (20, 10))\n",
    "sns.scatterplot(data = total_df, y = 'perc_area', x = 'split_time', ax = ax, hue = 'line', palette=line_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e178ddd3-f957-46b5-8c27-d0d61e22cfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = total_df[~((total_df['split_time'] < 25) & (total_df['perc_area'] > 10))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614da1f6-2098-4436-af7a-346b54c2fddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.kdeplot(np.log10(total_df['area_error']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56822491-22bb-4b24-b467-f7f51ab47900",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = total_df[total_df['area_error'] < 5]\n",
    "total_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e25475c-38da-41b5-afbc-415d8bcf591d",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_max = total_df.groupby('line')['n_split'].idxmax()\n",
    "\n",
    "# Filter the DataFrame using these indices\n",
    "filtered_df = total_df.drop(idx_max)\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71905092-dc30-4a59-97c0-8593552f1938",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df['logArea'] = np.log10(total_df['Area (microm2)'] + 0.000001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef26e23-4c83-4bb1-96e4-de32f7593217",
   "metadata": {},
   "source": [
    "# Growth curves total area - by line\n",
    "Here we fitted a polynomial regression function of order 3 (exploratory to look at what type of shapes we expect from the curves):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942cd6a0-2436-4597-9f8e-58047cf88ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = total_df.line.unique().tolist()\n",
    "order.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e65616f-2715-4fd3-a0a3-ae870cffaa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"ticks\")\n",
    "\n",
    "# Initialize a grid of plots with an Axes for each walk\n",
    "grid = sns.FacetGrid(total_df.sort_values(by = 'split_time'), col=\"line\", hue = 'line', palette=line_palette,\n",
    "                     col_wrap=4, height=5, col_order = order)\n",
    "\n",
    "\n",
    "# Draw a line plot to show the trajectory of each random walk\n",
    "grid.map(sns.regplot, \"split_time\", \"Area (mm2)\", order = 3)\n",
    "\n",
    "grid.set_axis_labels(\"Time point post split\", \"Area (mm2)\")\n",
    "\n",
    "# Adjust the arrangement of the plots\n",
    "grid.fig.tight_layout(w_pad=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac4ebf3-1b1d-4c83-b009-efdc3f75cdec",
   "metadata": {},
   "source": [
    "Without fitting any regression (line goes through the mean and the highligthed data around is the standard deviation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b564527c-677a-4978-971a-896f76391900",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"ticks\")\n",
    "\n",
    "# Initialize a grid of plots with an Axes for each walk\n",
    "grid = sns.FacetGrid(total_df.sort_values(by = 'split_time'), col=\"line\", hue = 'line', palette=line_palette,\n",
    "                     col_wrap=4, height=5, col_order = order)\n",
    "\n",
    "# Draw a line plot to show the trajectory of each random walk\n",
    "grid.map(sns.lineplot, \"split_time\", \"Area (mm2)\", markers = True)\n",
    "\n",
    "grid.set_axis_labels(\"Time point post split\", \"Total Area (pixels)\")\n",
    "\n",
    "# Adjust the arrangement of the plots\n",
    "grid.fig.tight_layout(w_pad=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4021f919-7f27-4271-a484-5fcbea3f250a",
   "metadata": {},
   "source": [
    "We use the __area__ then average all the FOV for a specific time points in each line. The plot is composed by:\n",
    "* a solid blue line, that is the smoothed version of this growth curve (using the function [`gaussian_filter1d`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.gaussian_filter1d.html) from numpy), \n",
    "* the red around that it is the standard deviation\n",
    "* the dotted grey line that is the original signal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48d76d0-6461-4272-9085-56ebf1f6964d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4, 3, figsize=(30, 21), gridspec_kw={'hspace': 0.7})\n",
    "ax = ax.flatten()\n",
    "\n",
    "for ax_index, line in enumerate(total_df.line.unique()):\n",
    "    sub = total_df[(total_df.line == line) & (total_df.n_split != 'day')].sort_values(by='datetime')\n",
    "    mean_st = sub.groupby('split_time')['Area (mm2)'].mean()\n",
    "    std_st = sub.groupby('split_time')['Area (mm2)'].std()\n",
    "    y_pos = mean_st.index\n",
    "    ydata = sub['Area (microm2)'].values\n",
    "    xdata = sub.split_time.values.astype('int')\n",
    "    farray = mean_st.values\n",
    "\n",
    "    # Smoothing\n",
    "    farray_smooth = gaussian_filter1d(farray, sigma=3)\n",
    "\n",
    "    # Error formatting\n",
    "    upper_err = gaussian_filter1d(farray + (std_st / 2).values, sigma=3)\n",
    "    lower_err = gaussian_filter1d(farray - (std_st / 2).values, sigma=3)\n",
    "\n",
    "    ax[ax_index].scatter(xdata, ydata)\n",
    "    ax[ax_index].plot(y_pos, farray, '--', linewidth=0.7, color='k', alpha=0.45)\n",
    "    ax[ax_index].plot(y_pos, farray_smooth, color='#2374AB')\n",
    "    ax[ax_index].fill_between(y_pos, upper_err, lower_err, color='crimson', alpha=0.2)\n",
    "\n",
    "    # Use meaningful limits for better visualization\n",
    "    ax[ax_index].set_ylim(0, np.max(farray) * 1.25)\n",
    "\n",
    "    # Rotate x-axis labels for better readability\n",
    "    ax[ax_index].tick_params(axis='x', rotation=90)\n",
    "\n",
    "    # Set axis labels and title\n",
    "    ax[ax_index].set_title(f'Line {line}')\n",
    "    ax[ax_index].set_ylabel('Total area')\n",
    "    ax[ax_index].set_xlabel('Time point after split')\n",
    "\n",
    "plt.tight_layout()  # Adjust layout to prevent overlapping\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef04903b-4130-4cf1-8666-269824aca523",
   "metadata": {},
   "source": [
    "# Growth curves total area - by line and split\n",
    "Here we fitted a polynomial regression function of order 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6537e70-61a9-4146-8774-ca03c4eb71dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"ticks\")\n",
    "\n",
    "split_palette = {'1': '#264653', '2': '#2a9d8f', '3': '#8ab17d', '4': '#e9c46a', '5': '#f4a261', '6': '#e76f51'}\n",
    "line_split_palette = {}\n",
    "\n",
    "for i in total_df.line_n_split.unique():\n",
    "    split_n = i.split('_')[-1]\n",
    "    line_split_palette[i] = split_palette[split_n]\n",
    "\n",
    "custom_handles = [Line2D([0], [0], color=color, lw=2) for color in split_palette.values()]\n",
    "grid = sns.FacetGrid(total_df.sort_values(by = 'split_time'), col=\"line\", hue = 'line_n_split', palette=line_split_palette,\n",
    "                     col_wrap=4, height=5, col_order = order)\n",
    "grid.map(sns.lineplot, \"split_time\", \"Area (mm2)\", markers = True)\n",
    "\n",
    "grid.add_legend()\n",
    "if grid._legend:\n",
    "    grid._legend.remove()  \n",
    "\n",
    "legend = grid.fig.legend(custom_handles, split_palette.keys(), ncol=2, frameon=False, bbox_to_anchor = (1.2,1), fontsize = 25)\n",
    "\n",
    "legend.set_title('Passage number', prop={'size': 30})\n",
    "\n",
    "for ax in grid.axes.flat:\n",
    "    ax.set_title(ax.get_title(), fontsize=35)\n",
    "\n",
    "# Increase the size of x and y tick labels\n",
    "for ax in grid.axes.flat:\n",
    "    ax.tick_params(axis='x', labelsize=20)\n",
    "    ax.tick_params(axis='y', labelsize=20)\n",
    "\n",
    "grid.set_axis_labels(\"Hours after splitting\", \"Total area (mm2)\", fontsize = 25)\n",
    "grid.fig.tight_layout(w_pad=1)\n",
    "grid.fig.savefig('./figures/raw_GC_iPSC_dividedSplit.svg', dpi = 300, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f199e7-51ec-463a-9bb5-5d37c4944eb5",
   "metadata": {},
   "source": [
    "I need to filter out the combination of \"line\" - \"number of split\" that do not have enough data point to fit an order 3 polynomial regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38587ed0-8ecf-42d3-8c8f-d09c9085445f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"ticks\")\n",
    "\n",
    "boolean_sel = pd.Series(total_df.groupby(['line_n_split'])['split_time'].count() > 5)\n",
    "boolean_sel = boolean_sel[boolean_sel]\n",
    "filtered_total = total_df[total_df.line_n_split.isin(boolean_sel.index)]\n",
    "\n",
    "# Initialize a grid of plots with an Axes for each walk\n",
    "grid = sns.FacetGrid(filtered_total.sort_values(by = 'split_time'), col=\"line_n_split\", hue = 'line', palette=line_palette,\n",
    "                     col_wrap=4, height=5, col_order = order)\n",
    "\n",
    "grid.map(sns.regplot, \"split_time\", \"Area (microm2)\", order = 3)\n",
    "\n",
    "# Adjust the arrangement of the plots\n",
    "grid.fig.tight_layout(w_pad=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0346e0-1637-43c1-a7f7-a7f1fce34d3a",
   "metadata": {},
   "source": [
    "We use the __area__ then average all the FOV for a specific time points in each line at each split. The plot is composed by:\n",
    "* a solid blue line, that is the smoothed version of this growth curve (using the function [`gaussian_filter1d`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.gaussian_filter1d.html) from numpy), \n",
    "* the red around that it is the standard deviation\n",
    "* the dotted grey line that is the original signal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df6a2dd-b508-4122-9541-5a4a313949ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(9,5, figsize = (5*10, 7*9), gridspec_kw={'hspace': 0.7})\n",
    "ax = ax.flatten().T\n",
    "ax_index = 0\n",
    "summary_dfs_dict = {}\n",
    "\n",
    "for l in order:\n",
    "\n",
    "    sub = total_df[total_df.line == l]\n",
    "    sub = sub.sort_values(by = 'datetime')\n",
    "    sub = sub[sub.n_split != 'day']\n",
    "\n",
    "    splits = sub.n_split.unique().tolist()\n",
    "    splits.sort()\n",
    "\n",
    "    for split in splits:\n",
    "\n",
    "        subsub = sub[sub.n_split == split]\n",
    "\n",
    "        if len(subsub.split_time.unique()) > 5:\n",
    "            \n",
    "            ydata = subsub['Area (microm2)'].values\n",
    "            xdata = subsub.split_time.values.astype('int')\n",
    "    \n",
    "            \n",
    "            # user defined function,\n",
    "            # with `area_sum` return the sum of the areas of all the field of view captured for that line at that time point\n",
    "            summary_df = preprocess(subsub, original_v='Area (microm2)', final_output='mean')\n",
    "\n",
    "            summary_dfs_dict[f'{l}_split_{split}'] = summary_df\n",
    "            \n",
    "            farray = np.array(summary_df['mean'])\n",
    "    \n",
    "            y_pos = summary_df.split_time.values\n",
    "    \n",
    "            # Smoothing\n",
    "            farray_smooth = gaussian_filter1d(farray, sigma=3)\n",
    "    \n",
    "            # Error formatting\n",
    "            upper_err = gaussian_filter1d(farray + (summary_df['stds'] / 2), sigma=3)\n",
    "            lower_err = gaussian_filter1d(farray - (summary_df['stds'] / 2), sigma=3)\n",
    "    \n",
    "            ax[ax_index].scatter(xdata, ydata)\n",
    "            ax[ax_index].plot(y_pos, farray, '--', linewidth=0.7, color='k', alpha=0.45)\n",
    "            ax[ax_index].plot(y_pos, farray_smooth, color = '#2374AB')\n",
    "            ax[ax_index].fill_between(y_pos, upper_err, lower_err, color='crimson', alpha=0.2)\n",
    "            #ax[ax_index].errorbar(y_pos, farray, yerr=summary_df['stds'], fmt='none', color='crimson', alpha=0.5)\n",
    "            #\n",
    "            ax[ax_index].set_ylim(0, np.max(farray)+(np.max((farray)*25)/100))\n",
    "            ax[ax_index].xaxis.set_tick_params(rotation=90)\n",
    "            ax[ax_index].set_title(f'{l}_split_{split}')\n",
    "            ax[ax_index].set_ylabel('Total area')\n",
    "            ax[ax_index].set_xlabel('Time point')\n",
    "            ax_index += 1\n",
    "            \n",
    "        else:\n",
    "            print(f'Skipped split {subsub.n_split.values[0]} of line {subsub.line.values[0]}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696bad7f-c7ab-46b2-a74f-d4e85406a30f",
   "metadata": {},
   "source": [
    "# Growth curves log total area\n",
    "\n",
    "We use the __logarithm of the area__ then sum all the FOV for a specific time points in each line at each split. The plot is composed by:\n",
    "* a solid blue line, that is the smoothed version of this growth curve (using the function [`gaussian_filter1d`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.gaussian_filter1d.html) from numpy), \n",
    "* the red around that it is the standard deviation\n",
    "* the dotted grey line that is the original signal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216c2934-07e9-4da2-8e87-ef6f3dc5fcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(10,5, figsize = (5*10, 7*9), gridspec_kw={'hspace': 0.7})\n",
    "ax = ax.flatten().T\n",
    "ax_index = 0\n",
    "\n",
    "for l in order:\n",
    "\n",
    "    sub = total_df[total_df.line == l]\n",
    "    sub = sub.sort_values(by = 'datetime')\n",
    "    sub = sub[sub.n_split != 'day']\n",
    "\n",
    "    splits = sub.n_split.unique().tolist()\n",
    "    splits.sort()\n",
    "\n",
    "    for split in splits:\n",
    "\n",
    "        subsub = sub[sub.n_split == split]\n",
    "\n",
    "        \n",
    "        # user defined function,\n",
    "        # with `area_sum` return the sum of the areas of all the field of view captured for that line at that time point\n",
    "        summary_df = preprocess(subsub, original_v='logArea', final_output='area_sum')\n",
    "        \n",
    "        farray = np.array(summary_df['area_sum'])\n",
    "\n",
    "        y_pos = summary_df.datetime.values\n",
    "\n",
    "        # Smoothing\n",
    "        farray_smooth = gaussian_filter1d(farray, sigma=1)\n",
    "\n",
    "        # Error formatting\n",
    "        upper_err = gaussian_filter1d(farray + (summary_df['stds'] / 2), sigma=1)\n",
    "        lower_err = gaussian_filter1d(farray - (summary_df['stds'] / 2), sigma=1)\n",
    "\n",
    "        ax[ax_index].plot(y_pos, farray, '--', linewidth=0.7, color='k', alpha=0.45)\n",
    "        ax[ax_index].plot(y_pos, farray_smooth, color = '#2374AB')\n",
    "        ax[ax_index].fill_between(y_pos, upper_err, lower_err, color='crimson', alpha=0.2)\n",
    "        #\n",
    "        ax[ax_index].set_ylim(0, np.max(farray)+(np.max((farray)*25)/100))\n",
    "        ax[ax_index].xaxis.set_tick_params(rotation=90)\n",
    "        ax[ax_index].set_title(f'{l}_split_{split}')\n",
    "        ax[ax_index].set_ylabel('Log total area')\n",
    "        ax[ax_index].set_xlabel('Time point')\n",
    "        ax_index += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b28ab5-bcd0-4eab-9cf9-63f8223d0220",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = total_df.line.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6db9f1-8f61-4188-8e67-8785255e5ef8",
   "metadata": {},
   "source": [
    "# Discrete derivative of the curves - per line per split\n",
    "\n",
    "We use the total area and then sum all the FOV for a specific time points in each line at each split. Then we smoothed it with [`gaussian_filter1d`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.gaussian_filter1d.html) and computed the [diff](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.diff.html), corresponding to the first discrete derivative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fe6886-ec97-4a6d-84ed-cefaf22dfa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_deriv_curves = {}\n",
    "\n",
    "fig, ax = plt.subplots(10,5, figsize = (5*10, 7*9), gridspec_kw={'hspace': 0.7})\n",
    "ax = ax.flatten().T\n",
    "ax_index = 0\n",
    "\n",
    "for l in total_df.line.unique():\n",
    "    \n",
    "    #color = color_dict[l]\n",
    "\n",
    "    sub = total_df[total_df.line == l]\n",
    "    sub = sub.sort_values(by = 'datetime')\n",
    "    sub = sub[sub.n_split != 'day']\n",
    "\n",
    "    for split in sub.n_split.unique():\n",
    "\n",
    "        subsub = sub[sub.n_split == split]\n",
    "\n",
    "        # user defined function,\n",
    "        # with `area_sum` return the sum of the areas of all the field of view captured for that line at that time point\n",
    "        summary_df = preprocess(subsub, original_v='Area (microm2)', final_output='mean')\n",
    "        \n",
    "        summary_df = summary_df.sort_values('split_time')\n",
    "        \n",
    "        summary_df['smoothed'] = gaussian_filter1d(summary_df['mean'], 3)\n",
    "        summary_df['derivative'] = summary_df['smoothed'].diff() / summary_df['split_time'].diff()\n",
    "\n",
    "        discrete_deriv_curves[f'{l}_split_{split}'] = summary_df\n",
    "        \n",
    "        farray = np.array(summary_df['derivative'])\n",
    "        \n",
    "        y_pos = summary_df.split_time.values\n",
    "        \n",
    "        ax[ax_index].errorbar(y_pos, farray, marker = 'o')\n",
    "        \n",
    "        ax[ax_index]\n",
    "\n",
    "        ax[ax_index].xaxis.set_tick_params(rotation=90)\n",
    "        ax[ax_index].set_title(f'{l}_split_{split}')\n",
    "        ax[ax_index].set_ylabel('Discrete derivative')\n",
    "        ax[ax_index].set_xlabel('Time point')\n",
    "        ax_index += 1\n",
    "        \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdde2e65-d844-4788-a9d3-9f224514b816",
   "metadata": {},
   "source": [
    "# Discrete derivative of the curves - per line\n",
    "\n",
    "We collected the results for each line and each split and we can use it to converge to a single result for each line using as replicates the splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4b598c-0a1f-469f-a7d2-0a527f3a5265",
   "metadata": {},
   "outputs": [],
   "source": [
    "deriv_df = pd.concat(discrete_deriv_curves.values(), keys = discrete_deriv_curves.keys()).reset_index()\n",
    "deriv_df['line'] = deriv_df['level_0'].apply(lambda x: x.split('_')[0])\n",
    "deriv_df['split'] = deriv_df['level_0'].apply(lambda x: x.split('_')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2a8fed-6b1a-4466-ab12-4f226d9debfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4,3, figsize = (5*4, 7*3), gridspec_kw={'hspace': 0.7})\n",
    "ax = ax.flatten().T\n",
    "ax_index = 0\n",
    "\n",
    "for line in deriv_df.line.unique():\n",
    "    \n",
    "    #color = color_dict[l]\n",
    "\n",
    "    sub = deriv_df[deriv_df.line == line]\n",
    "    \n",
    "    sub = sub.sort_values('split_time')\n",
    "\n",
    "    sub['smoothed'] = gaussian_filter1d(sub['derivative'], sigma = 3)\n",
    "\n",
    "    sns.lineplot(data = sub, y = 'smoothed', x = 'split_time', hue = 'split', ax = ax[ax_index], errorbar='sd', markers = True, palette=split_palette)\n",
    "    ax[ax_index].xaxis.set_tick_params(rotation=90)\n",
    "    ax[ax_index].set_title(f'{line}')\n",
    "    ax[ax_index].set_ylabel('Discrete derivative')\n",
    "    ax[ax_index].set_xlabel('Time point')\n",
    "    ax_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9810bc-40c1-44d1-b318-34bd96b72564",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4,3, figsize = (5*4, 7*3)) #, gridspec_kw={'hspace': 0.7})\n",
    "ax = ax.flatten().T\n",
    "ax_index = 0\n",
    "\n",
    "for line in deriv_df.line.unique():\n",
    "    \n",
    "    #color = color_dict[l]\n",
    "\n",
    "    sub = deriv_df[deriv_df.line == line]\n",
    "    \n",
    "    sub = sub.sort_values('split_time')\n",
    "\n",
    "    sub['smoothed'] = gaussian_filter1d(sub['derivative'], sigma = 3)\n",
    "\n",
    "    sns.lineplot(data = sub, y = 'smoothed', x = 'split_time', ax = ax[ax_index], errorbar='sd', markers = True, err_style = 'bars')\n",
    "    ax[ax_index].xaxis.set_tick_params(rotation=90)\n",
    "    ax[ax_index].set_title(f'{line}')\n",
    "    ax[ax_index].set_ylabel('Discrete derivative')\n",
    "    ax[ax_index].set_xlabel('Time point')\n",
    "    ax_index += 1\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c41984e-ffee-420d-a360-7b9996658edf",
   "metadata": {},
   "source": [
    "# Cumulative  of the areas - per line per split\n",
    "\n",
    "We use the total area and then average all the FOV for a specific time points in each line at each split. Then we smoothed it with [`gaussian_filter1d`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.gaussian_filter1d.html) and computed the cumulative sum over the discrete differential of the growth. with the [`cumsum()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cumsum.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f5e68a-e63a-4d72-bc2f-49590410ebf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(9,5, figsize = (5*10, 7*9))\n",
    "ax = ax.flatten().T\n",
    "ax_index = 0\n",
    "\n",
    "order_line_n = total_df.line_n_split.unique().tolist()\n",
    "order_line_n.sort()\n",
    "\n",
    "for line_n in order_line_n:\n",
    "    \n",
    "    sub = total_df[total_df.line_n_split == line_n]\n",
    "    #sub = sub[~sub.index.duplicated()]\n",
    "    sub = sub.sort_values('split_time')\n",
    "\n",
    "    if len(sub.split_time.unique()) > 5:\n",
    "        \n",
    "        #sub['smoothed'] = sub.groupby('line_n_split')['Area (microm2)'].apply(gaussian_filter1d, sigma = 3).loc[line_n]\n",
    "        y = sub.groupby('split_time')['Area (mm2)'].mean().cumsum().values\n",
    "        x = sub.split_time.unique()\n",
    "        \n",
    "        sns.lineplot(y = y, x = x, ax = ax[ax_index], errorbar='sd', markers = True, err_style='bars')\n",
    "        ax[ax_index].xaxis.set_tick_params(rotation=90)\n",
    "        ax[ax_index].set_title(f'{line_n}')\n",
    "        ax[ax_index].set_ylabel('Cumulative of mean total area')\n",
    "        ax[ax_index].set_xlabel('Time point')\n",
    "        ax_index += 1\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1164fc63-af3e-459a-aae6-1addf9d91130",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"white\", palette=\"Paired\", color_codes=True)\n",
    "fig, ax = plt.subplots(figsize=(7,5))\n",
    "labels = []\n",
    "lc = []\n",
    "handles = []\n",
    "all_lines = {}\n",
    "\n",
    "total_df_no_first = total_df[total_df.n_split != '1'].copy()\n",
    "\n",
    "for l in total_df.line.unique():\n",
    "    \n",
    "    color = line_palette[l]\n",
    "\n",
    "    sub = total_df[total_df.line == l]\n",
    "    sub = sub.sort_values(by = 'datetime')\n",
    "    sub = sub[sub.n_split != 'day']\n",
    "\n",
    "    for split in sub.n_split.unique():\n",
    "\n",
    "        subsub = sub[sub.n_split == split]\n",
    "\n",
    "        # user defined function,\n",
    "        # with `area_sum` return the sum of the areas of all the field of view captured for that line at that time point\n",
    "        summary_df = preprocess(subsub, original_v='Area (mm2)', final_output='mean')\n",
    "        \n",
    "        summary_df = summary_df.sort_values('split_time')\n",
    "        \n",
    "        summary_df['smoothed'] = gaussian_filter1d(summary_df['mean'], 1)\n",
    "        summary_df['cumulative'] = summary_df['smoothed'].cumsum()\n",
    "        \n",
    "        farray = np.array(summary_df['cumulative'])\n",
    "        \n",
    "        y_pos = summary_df.split_time.values\n",
    "\n",
    "        line, = ax.plot(y_pos, farray, color = color, marker = '.')\n",
    "        ax.xaxis.set_tick_params(rotation=90)\n",
    "        all_lines[f'{l}_{split}'] = line\n",
    "\n",
    "    labels.append(l)\n",
    "    handles.append(line)\n",
    "    lc.append(color)\n",
    "    \n",
    "plt.legend(handles, labels, bbox_to_anchor = (1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4354e3-61da-4c7a-bdb6-b5946ee9c7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = total_df.line.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf12e6b8-5e88-4e9a-ade2-75e0a0c0e294",
   "metadata": {},
   "outputs": [],
   "source": [
    "highlight_growth_curves(all_lines, xlabel = 'Hours from split', ylabel = 'Cumulative growth', lines = lines, fontsize = 20)\n",
    "#plt.savefig('growth_curve_per_line.pdf', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5ffa3e-39ab-42c6-a58b-c0293d8289ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(5,9, figsize = (5*12, 8*5))\n",
    "ax = ax.flatten().T\n",
    "ax_index = 0\n",
    "\n",
    "fitted_param = {}\n",
    "\n",
    "def exp_model(t, a, b):\n",
    "    return a * np.exp(b * t)\n",
    "\n",
    "for line_n in order_line_n:\n",
    "\n",
    "    fitted_param[line_n] = {}\n",
    "    sub = total_df[total_df.line_n_split == line_n]\n",
    "    sub = sub.sort_values('split_time')\n",
    "    \n",
    "    if len(sub.split_time.unique()) > 5:\n",
    "        # Calculate the cumulative sum of the mean total area for each split_time\n",
    "        y = sub.groupby('split_time')['Area (mm2)'].mean().cumsum().values\n",
    "        x = np.array(sub.split_time.unique())\n",
    "        hue = [line_n.split('_')[0]]*len(y)\n",
    "\n",
    "        try:\n",
    "            popt, pcov = curve_fit(exp_model, x, y, p0=(max(y), 0.1))\n",
    "\n",
    "            fitted_param[line_n]['a'] = popt[0]\n",
    "            fitted_param[line_n]['rate'] = popt[1]\n",
    "            fitted_param[line_n]['mean_cum'] = y\n",
    "            fitted_param[line_n]['split_time'] = x\n",
    "            \n",
    "            a, b = popt\n",
    "            \n",
    "            # Generate fitted y values\n",
    "            y_fitted = exp_model(x, a, b)\n",
    "\n",
    "            fitted_param[line_n]['y_fitted'] = y_fitted\n",
    "            fitted_param[line_n]['MSLE'] = mean_squared_log_error(y, y_fitted)\n",
    "            fitted_param[line_n]['r2'] = r2_score(y, y_fitted)\n",
    "            \n",
    "            sns.lineplot(y = y_fitted, x = x, ax = ax[ax_index], markers = True, hue = hue, palette=line_palette, linewidth = 5, legend = None)\n",
    "            sns.scatterplot(y = y, x = x, ax = ax[ax_index], markers = True, hue = hue, palette=line_palette, s = 150, legend=None)\n",
    "            ax[ax_index].xaxis.set_tick_params(rotation=90)\n",
    "            ax[ax_index].set_title(f'{line_n}', fontsize = 40)\n",
    "            ax[ax_index].set_ylabel('Cumulative area (mm2)', fontsize = 35)\n",
    "            ax[ax_index].set_xlabel('Time point', fontsize = 35)\n",
    "            _ = ax[ax_index].set_xticklabels(ax[ax_index].get_xticklabels(), fontsize = 30)\n",
    "            _ = ax[ax_index].set_yticklabels(ax[ax_index].get_yticklabels(), fontsize = 30)\n",
    "            ax_index += 1\n",
    "        \n",
    "        except RuntimeError as e:\n",
    "            print(f\"Fitting failed for line_n {line_n}: {e}\")\n",
    "            \n",
    "plt.tight_layout()\n",
    "plt.savefig('./figures/Fitted_cum_area_per_split.svg', dpi = 300, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff8d16a-f3e2-4ad5-bd37-f2fe45fd35b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"white\", palette=\"Paired\", color_codes=True)\n",
    "fig, ax = plt.subplots(figsize=(7,5))\n",
    "labels = []\n",
    "lc = []\n",
    "handles = []\n",
    "all_lines = {}\n",
    "\n",
    "total_df_no_first = total_df[total_df.n_split != '1'].copy()\n",
    "\n",
    "for l in total_df.line.unique():\n",
    "    \n",
    "    color = line_palette[l]\n",
    "\n",
    "    sub = total_df[total_df.line == l]\n",
    "    sub = sub.sort_values(by = 'datetime')\n",
    "    sub = sub[sub.n_split != 'day']\n",
    "\n",
    "    for split in sub.n_split.unique():\n",
    "\n",
    "\n",
    "        subsub = sub[sub.n_split == split]\n",
    "\n",
    "        if len(subsub.split_time.unique()) > 5:\n",
    "\n",
    "            # user defined function,\n",
    "            # with `area_sum` return the sum of the areas of all the field of view captured for that line at that time point\n",
    "            summary_df = preprocess(subsub, original_v='Area (mm2)', final_output='mean')\n",
    "            \n",
    "            summary_df = summary_df.sort_values('split_time')\n",
    "            summary_df['cumulative'] = summary_df['mean'].cumsum()\n",
    "            \n",
    "            farray = np.array(summary_df['cumulative'].values)\n",
    "            y_pos = summary_df.split_time.values\n",
    "    \n",
    "            popt, pcov = curve_fit(exp_model, y_pos, farray, p0=(max(farray), 0.1))\n",
    "            \n",
    "            a, b = popt\n",
    "    \n",
    "            y_fitted = exp_model(y_pos, a, b)\n",
    "    \n",
    "            line, = ax.plot(y_pos, y_fitted, color = color, marker = '.')\n",
    "            ax.xaxis.set_tick_params(rotation=90)\n",
    "            all_lines[f'{l}_{split}'] = line\n",
    "    \n",
    "        labels.append(l)\n",
    "        handles.append(line)\n",
    "        lc.append(color)\n",
    "    \n",
    "plt.legend(handles, labels, bbox_to_anchor = (1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc61252-1421-4c5f-b26a-dcf2d5e46679",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = total_df.line.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e6bbcb-5baa-4f46-b71e-792243be4e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "highlight_growth_curves(all_lines, xlabel = 'Hours from split', ylabel = 'Cumulative area (mm2)', lines = lines, fontsize = 20)\n",
    "plt.savefig('./figures/cumulative_growth_curve_per_line.svg', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be1430a-3d65-4d70-87c5-ede28fa3f7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_df = pd.DataFrame.from_dict(fitted_param).T\n",
    "fitted_df['Line'] = fitted_df.reset_index()['index'].apply(lambda x: x.split('_')[0]).values\n",
    "fitted_df['split'] = fitted_df.reset_index()['index'].apply(lambda x: x.split('_')[1]).values\n",
    "fitted_df = fitted_df[~fitted_df.a.isna()]\n",
    "#fitted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baceeaa-35f4-4119-b869-ba01111cb790",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_df_filtered = fitted_df[fitted_df['r2'] > 0.9]\n",
    "fitted_df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4e0c60-c20c-4b94-be7f-f364be34e1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.barplot(data = fitted_df_filtered, x = 'split', y = 'rate', order = ['1', '2', '3', '4', '5', '6'], ax = ax)#, hue = 'Line', palette=line_palette)\n",
    "_ = ax.set_ylabel('Growth rate', fontsize = 20)\n",
    "_ = ax.set_yticklabels(ax.get_yticklabels(), fontsize = 15)\n",
    "_ = ax.set_xlabel('Passage', fontsize = 20)\n",
    "_ = ax.set_xticklabels(ax.get_xticklabels(), fontsize = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f2ac1e-98be-4029-8c8f-c59e9bad3443",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (10,4))\n",
    "fitted_df_filtered['split'] = fitted_df_filtered['split'].astype('int')\n",
    "sns.lineplot(data = fitted_df_filtered, x = 'split', y = 'rate', hue = 'Line',\n",
    "              ax = ax, palette=line_palette)\n",
    "_ = ax.set_ylabel('Growth rate', fontsize = 20)\n",
    "_ = ax.set_yticklabels(ax.get_yticklabels(), fontsize = 15)\n",
    "_ = ax.set_xlabel('Passage', fontsize = 20)\n",
    "_ = ax.set_xticklabels(ax.get_xticklabels(), fontsize = 15)\n",
    "ax.legend(bbox_to_anchor = (1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ecb218-67a9-49bf-ac11-5a29a4a625bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.boxplot(data = fitted_df_filtered, x = 'Line', y = 'rate', ax = ax, palette=line_palette)\n",
    "_ = ax.set_ylabel('Rate of area growth', fontsize = 20)\n",
    "_ = ax.set_yticklabels(ax.get_yticklabels(), fontsize = 15)\n",
    "_ = ax.set_xlabel('Passage', fontsize = 20)\n",
    "_ = ax.set_xticklabels(ax.get_xticklabels(), fontsize = 15, rotation = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736d8ba5-a829-4cf1-b31d-a166b667267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_df_filtered.sort_values(by = 'rate').to_csv('../../data/csv/iPSC_fitted_exp_area_sum_per_split.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cae4496-29a9-4037-b4d9-4d963ab36d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_df_filtered.sort_values(by = 'rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae95ec1-f610-47ce-8048-395685ef3240",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(fitted_df.groupby('Line')['rate'].mean().sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abd6965-9488-4b1a-8540-86d586542dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tot = []\n",
    "\n",
    "for line_n in fitted_df.index:\n",
    "    sub = fitted_df.loc[line_n]\n",
    "    data = pd.DataFrame({'mean_cum': sub['mean_cum'], 'split_time': sub['split_time'], 'line_n': [line_n] * len(sub['mean_cum'])})\n",
    "    data_tot.append(data)\n",
    "\n",
    "data_tot = pd.concat(data_tot)\n",
    "\n",
    "data_tot['Line'] = data_tot['line_n'].apply(lambda x: x.split('_')[0]).values\n",
    "data_tot['split'] = data_tot['line_n'].apply(lambda x: x.split('_')[1]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b1372a-f98b-46ce-882b-e012d8664186",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4,3, figsize = (20, 20))\n",
    "ax = ax.flatten().T\n",
    "ax_index = 0\n",
    "fitted_param_line = {}\n",
    "\n",
    "for line in order:\n",
    "\n",
    "    fitted_param_line[line] = {}\n",
    "    sub = data_tot[data_tot.Line == line]\n",
    "    sub = sub.sort_values('split_time')\n",
    "    \n",
    "    if len(sub.split_time.unique()) > 5:\n",
    "        # Calculate the cumulative sum of the mean total area for each split_time\n",
    "        y = sub['mean_cum'].cumsum().values\n",
    "        x = np.array(sub.split_time)\n",
    "\n",
    "        try:\n",
    "            popt, pcov = curve_fit(exp_model, x, y, p0=(max(y), 0.1))\n",
    "\n",
    "            fitted_param_line[line]['intercept'] = popt[0]\n",
    "            fitted_param_line[line]['rate'] = popt[1]\n",
    "            fitted_param_line[line]['mean_cum'] = y\n",
    "            fitted_param_line[line]['split_time'] = x\n",
    "            \n",
    "            a, b = popt\n",
    "            \n",
    "            # Generate fitted y values\n",
    "            y_fitted = exp_model(x, a, b)\n",
    "\n",
    "            fitted_param_line[line]['y_fitted'] = y_fitted\n",
    "            fitted_param_line[line]['MSLE'] = mean_squared_log_error(y, y_fitted)\n",
    "            fitted_param_line[line]['r2'] = r2_score(y, y_fitted)\n",
    "            \n",
    "            sns.lineplot(y = y_fitted, x = x, ax = ax[ax_index], markers = True)\n",
    "            sns.scatterplot(y = y, x = x, ax = ax[ax_index], markers = True)\n",
    "            ax[ax_index].xaxis.set_tick_params(rotation=90)\n",
    "            ax[ax_index].set_title(f'{line}', fontsize = 30)\n",
    "            ax[ax_index].set_ylabel('Increase in area ', fontsize = 20)\n",
    "            ax[ax_index].set_xlabel('Time point', fontsize = 20)\n",
    "            _ = ax[ax_index].set_xticklabels(ax[ax_index].get_xticklabels(), fontsize = 15)\n",
    "            _ = ax[ax_index].set_yticklabels(ax[ax_index].get_yticklabels(), fontsize = 15)\n",
    "            ax_index += 1\n",
    "        \n",
    "        except RuntimeError as e:\n",
    "            print(f\"Fitting failed for line_n {line_n}: {e}\")\n",
    "            \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ea5c41-6df5-4469-84d4-627d1becceb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_df_line = pd.DataFrame.from_dict(fitted_param_line).T\n",
    "fitted_df_line = fitted_df_line[~fitted_df_line.intercept.isna()]\n",
    "fitted_df_line.sort_values('rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c293a202-67e0-4fdc-bcb1-5de911489e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_df.r2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29206457-f1a5-4792-9aaf-17fc73feff0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_df_filtered.r2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c384a128-a0e0-4f5c-80d2-e19e11547076",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_df_line.r2.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71556878-c31f-4fdf-9787-b6f25e5c1331",
   "metadata": {},
   "source": [
    "# Cumulative sum of the discrete derivative of the curves - per line per split\n",
    "\n",
    "We use the logarithm of the area and then sum all the FOV for a specific time points in each line at each split. Then we smoothed it with [`gaussian_filter1d`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.gaussian_filter1d.html) and computed the [diff](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.diff.html), corresponding to the first discrete derivative. We then use the [`cumsum()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.cumsum.html) function to obtain the cumulative sum over the discrete differential of the growth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc13f20-bc5a-40fd-b328-509ddd8e378d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(10,5, figsize = (5*10, 7*9), gridspec_kw={'hspace': 0.7})\n",
    "ax = ax.flatten().T\n",
    "ax_index = 0\n",
    "\n",
    "for l in total_df.line.unique():\n",
    "    \n",
    "    #color = color_dict[l]\n",
    "\n",
    "    sub = total_df[total_df.line == l]\n",
    "    sub = sub.sort_values(by = 'datetime')\n",
    "    sub = sub[sub.n_split != 'day']\n",
    "\n",
    "    for split in sub.n_split.unique():\n",
    "\n",
    "        subsub = sub[sub.n_split == split]\n",
    "\n",
    "        \n",
    "        # user defined function,\n",
    "        # with `area_sum` return the sum of the areas of all the field of view captured for that line at that time point\n",
    "        summary_df = preprocess(subsub, original_v='Area (microm2)', final_output='mean')\n",
    "        \n",
    "        summary_df = summary_df.sort_values('split_time')\n",
    "        \n",
    "        summary_df['smoothed'] = gaussian_filter1d(summary_df['mean'], 3)\n",
    "        summary_df['derivative'] = summary_df['smoothed'].diff() / summary_df['split_time'].diff()\n",
    "        summary_df['cumulative'] = summary_df['derivative'].cumsum()\n",
    "        \n",
    "        farray = np.array(summary_df['cumulative'])\n",
    "        \n",
    "        y_pos = summary_df.split_time.values\n",
    "        \n",
    "        ax[ax_index].errorbar(y_pos, farray, marker = 'o')\n",
    "\n",
    "        ax[ax_index].xaxis.set_tick_params(rotation=90)\n",
    "        ax[ax_index].set_title(f'{l}_split_{split}')\n",
    "        ax[ax_index].set_ylabel('Cumulative growth')\n",
    "        ax[ax_index].set_xlabel('Time point')\n",
    "        ax_index += 1\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb22b78a-805c-4f6c-8b1c-69d4566dfedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e195d7db-f593-42a4-b0b4-b78d55247cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"white\", palette=\"Paired\", color_codes=True)\n",
    "fig, ax = plt.subplots(figsize=(7,5))\n",
    "labels = []\n",
    "lc = []\n",
    "handles = []\n",
    "all_lines = {}\n",
    "\n",
    "total_df_no_first = total_df[total_df.n_split != '1'].copy()\n",
    "\n",
    "cumulative_dict_dfs = {}\n",
    "\n",
    "for l in total_df.line.unique():\n",
    "    \n",
    "    color = line_palette[l]\n",
    "\n",
    "    sub = total_df[total_df.line == l]\n",
    "    sub = sub.sort_values(by = 'datetime')\n",
    "    sub = sub[sub.n_split != 'day']\n",
    "\n",
    "    for split in sub.n_split.unique():\n",
    "\n",
    "\n",
    "        subsub = sub[sub.n_split == split]\n",
    "\n",
    "        if len(subsub.split_time.unique()) > 0:\n",
    "    \n",
    "            # user defined function,\n",
    "            # with `area_sum` return the sum of the areas of all the field of view captured for that line at that time point\n",
    "            summary_df = preprocess(subsub, original_v='Area (microm2)', final_output='mean')\n",
    "            \n",
    "            summary_df = summary_df.sort_values('split_time')\n",
    "            \n",
    "            summary_df['smoothed'] = gaussian_filter1d(summary_df['mean'], 3)\n",
    "            summary_df['derivative'] = summary_df['smoothed'].diff() / summary_df['split_time'].diff()\n",
    "            summary_df['cumulative'] = summary_df['derivative'].cumsum()\n",
    "    \n",
    "            cumulative_dict_dfs[f'{l}_{split}'] = summary_df\n",
    "            \n",
    "            farray = np.array(summary_df['cumulative'])\n",
    "            \n",
    "            y_pos = summary_df.split_time.values\n",
    "    \n",
    "            line, = ax.plot(y_pos, farray, color = color, marker = '.')\n",
    "            ax.xaxis.set_tick_params(rotation=90)\n",
    "            all_lines[f'{l}_{split}'] = line\n",
    "    \n",
    "            labels.append(l)\n",
    "            handles.append(line)\n",
    "            lc.append(color)\n",
    "    \n",
    "plt.legend(handles, labels, bbox_to_anchor = (1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e127d6-b91f-4442-8ecf-d9f64702c76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = total_df.line.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c5a5e3-970b-4dcc-82f0-8785c613a218",
   "metadata": {},
   "outputs": [],
   "source": [
    "highlight_growth_curves(all_lines, \n",
    "                        xlabel = 'Hours from split', \n",
    "                        ylabel = 'Cumulative growth', \n",
    "                        lines = lines, fontsize = 20)\n",
    "plt.savefig('./figures/cumulative_growth_curve_per_line.svg', dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17970d8f-a879-4b2e-a781-0b773aec1a38",
   "metadata": {},
   "source": [
    "## Fit linear model\n",
    "I fit here a linear regression model taking into account all the cumulatve sums of all the splits for each line. We extrapolate the slope as the rate of growth of the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ca2991-766c-47cc-8ad5-7b290ebc2de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_df = pd.concat(cumulative_dict_dfs.values(), keys = cumulative_dict_dfs.keys()).reset_index()\n",
    "cumulative_df['line'] = cumulative_df.level_0.apply(lambda x: x.split('_')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d535e4-be2d-40ff-9e3b-71545f6fb959",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32b8aa4-d64e-4d79-86e4-3ee75431168c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a grid of plots with an Axes for each walk\n",
    "grid = sns.FacetGrid(cumulative_df.sort_values(by = 'split_time'), col=\"line\", palette=line_palette,\n",
    "                     col_wrap=4, height=5)\n",
    "\n",
    "grid.map(sns.regplot, \"split_time\", \"cumulative\", order = 1)\n",
    "\n",
    "# Adjust the arrangement of the plots\n",
    "grid.fig.tight_layout(w_pad=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dca99d-e80d-403a-a59b-ce900c23754a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_model = {}\n",
    "for l in cumulative_df.line.unique():\n",
    "    \n",
    "    sub = cumulative_df[cumulative_df.line == l]\n",
    "    sub = sub.sort_values(by = 'datetime')\n",
    "\n",
    "    key = f'{l}'\n",
    "    fitted_model[key] = {}\n",
    "    fitted_model[key]['slope'], fitted_model[key]['intercept'], fitted_model[key]['rvalue'], fitted_model[key]['pvalue'], fitted_model[key]['stderr'] = stats.linregress(sub['split_time'], sub['cumulative'].fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb504eb-2564-4ca8-8e42-abf154383aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_model_df = pd.DataFrame.from_dict(fitted_model).T.reset_index()\n",
    "fitted_model_df['line'] = fitted_model_df['index'].apply(lambda x: x.split('_')[0])\n",
    "fitted_model_df.sort_values(by = 'slope')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be975cc4-130e-438d-befc-7ae269465de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_model_df.rvalue.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3d5763-90e9-4d0b-a877-02ee1e47f636",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_model_df.sort_values(by = 'slope').to_csv('../../data/csv/iPSC_fitted_lm_grouped.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
